{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import numpy as np\n",
    "tf.reset_default_graph() # THIS IS NECESSARY BEFORE MAKING NEW SESSION TO STOP IT ERRORING!!\n",
    "try:\n",
    "    sess\n",
    "except:\n",
    "    pass\n",
    "else:\n",
    "    sess.close()\n",
    "    del sess\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "n_inputs = 4  # == env.observation_space.shape[0]\n",
    "n_hidden = 20  # it's a simple task, we don't need more than this\n",
    "n_outputs = 2 # only outputs the probability of accelerating left\n",
    "initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "LR = 1e-2\n",
    "\n",
    "# 2. Build the neural network\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "Y = tf.placeholder(tf.int32, shape=[None])\n",
    "\n",
    "hidden = tf.layers.dense(X, n_hidden, activation=tf.nn.relu,\n",
    "                         kernel_initializer=initializer)\n",
    "hidden1 = tf.layers.dense(hidden, n_hidden, activation=tf.nn.relu,\n",
    "                         kernel_initializer=initializer)\n",
    "\n",
    "logits = tf.layers.dense(hidden1, n_outputs,\n",
    "                          kernel_initializer=initializer)\n",
    "outputs = tf.nn.softmax(logits)\n",
    "# 3. Select a random action based on the estimated probabilities\n",
    "# p_left_and_right = tf.concat(axis=1, values=[outputs, 1 - outputs])\n",
    "action = tf.multinomial(tf.log(outputs), num_samples=1)[0]\n",
    "\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(labels=Y, logits=logits)\n",
    "train_step = tf.train.AdamOptimizer(LR).minimize(loss)\n",
    "    \n",
    "tf.global_variables_initializer().run()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# a = np.expand_dims(np.random.rand(4),axis=0)\n",
    "# print(sess.run([logits,outputs,action], feed_dict={X: a}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/tensorflow/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "//anaconda/envs/tensorflow/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "//anaconda/envs/tensorflow/lib/python3.6/site-packages/numpy/core/_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "//anaconda/envs/tensorflow/lib/python3.6/site-packages/numpy/core/_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "//anaconda/envs/tensorflow/lib/python3.6/site-packages/numpy/core/_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training! 756\n",
      "training! 930\n",
      "training! 644\n",
      "training! 656\n",
      "training! 569\n",
      "training! 704\n",
      "training! 491\n",
      "training! 519\n",
      "training! 975\n",
      "training! 735\n",
      "training! 693\n",
      "training! 748\n",
      "training! 529\n",
      "training! 720\n",
      "training! 556\n",
      "training! 597\n",
      "training! 766\n",
      "training! 546\n",
      "training! 907\n",
      "training! 679\n",
      "training! 886\n",
      "training! 515\n",
      "training! 808\n",
      "training! 714\n",
      "training! 582\n",
      "training! 688\n",
      "training! 753\n",
      "training! 924\n",
      "training! 562\n",
      "training! 617\n",
      "training! 463\n",
      "training! 541\n",
      "training! 475\n",
      "training! 532\n",
      "training! 549\n",
      "training! 742\n",
      "training! 656\n",
      "training! 693\n",
      "training! 790\n",
      "training! 645\n",
      "training! 923\n",
      "training! 731\n",
      "training! 781\n",
      "training! 611\n",
      "training! 588\n",
      "training! 721\n",
      "training! 736\n",
      "training! 641\n",
      "training! 646\n",
      "training! 704\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "# env = gym.make('CartPole-v0')\n",
    "env = gym.make(\"CartPole-v0\").env\n",
    "i = 0\n",
    "rewards_t = []\n",
    "    \n",
    "while i < 50:\n",
    "    observation = env.reset()\n",
    "    acts = []\n",
    "    obvs = []\n",
    "    reward_t = 0\n",
    "    for t in range(1000):\n",
    "#         env.render()\n",
    "        act = sess.run(action, feed_dict={X: np.expand_dims(observation,axis=0)})[0]\n",
    "        acts.append(act)\n",
    "        obvs.append(observation)\n",
    "        observation, reward, done, info = env.step(act)\n",
    "        reward_t += reward\n",
    "        if done:\n",
    "            t_s.append(t)\n",
    "            rewards_t.append(reward_t)\n",
    "            if (reward_t > (np.mean(rewards_t[-10:-1]) + 0.5 * np.std(rewards_t[-10:-1]))):\n",
    "                print('training! %d' % reward_t)\n",
    "                sess.run(train_step, feed_dict={X: obvs, Y:acts})\n",
    "                max_t = t\n",
    "                i += 1\n",
    "            break\n",
    "#     if np.mean(rewards_t[-10:-1]) > 180:\n",
    "#        break\n",
    "            \n",
    "saver.save(sess, \"./my_policy_net_basic.ckpt\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from ./my_policy_net_basic.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/tensorflow/lib/python3.6/site-packages/gym/envs/classic_control/cartpole.py:137: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return self.viewer.render(return_rgb_array = mode=='rgb_array')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363.0\n"
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "rewardsum = 0\n",
    "env = gym.make(\"CartPole-v0\").env\n",
    "obs = env.reset()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_policy_net_basic.ckpt\")\n",
    "    for step in range(1000):\n",
    "        env.render(obs)\n",
    "        action_val = action.eval(feed_dict={X: obs.reshape(1, n_inputs)})\n",
    "        obs, reward, done, info = env.step(action_val[0])\n",
    "        rewardsum += reward\n",
    "        if done:\n",
    "            break\n",
    "env.close()\n",
    "print(rewardsum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
